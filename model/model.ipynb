{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfFI6GJH7OCh","executionInfo":{"status":"ok","timestamp":1701760136815,"user_tz":-420,"elapsed":8560,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"daf3ef0a-9cad-416f-fedf-606433d77a7e"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/chatbot-psc1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YEfPMQZv2Re","executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":23,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"1c1b179d-ec87-44c4-c981-bd0145c2295f"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/chatbot-psc1\n"]}]},{"cell_type":"markdown","metadata":{"id":"D5hyfKU160_T"},"source":["# 1. Import Library yang kita butuhkan\n","\n","- Pada perintah di bawah kami mengimport semua kebutuhan library yang kami butuhkan,\n","- Jika temen temen tidak mau import semua library yang di butuhkan dalam step 1 temen temen cukup import library json saja untuk menghubungkan dataset yang sudah kita buat.\n","\n","### Perlu di note sebelumnya di virtual environment kami sudah Install and import library yang di butuhkan seperti **tensorflow, keras, keras-models, pickle, nltk**\n","\n","Cara install:\n","\n","- pip install tensorflow\n","- pip install keras\n","- pip install keras-models\n","- pip install pickle\n","- pip install nltk\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"7tbryEXq60_c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":18,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"e0328e22-88fe-4915-ada4-9fa9857c235d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# import necessary libraries\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","import json\n","import pickle\n","\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers.legacy import SGD\n","import random\n","from keras.models import load_model"]},{"cell_type":"code","source":["# create an object of WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# importing the GL Bot corpus file for pre-processing\n","words=[]\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']\n","data_file = open(\"/content/drive/MyDrive/chatbot-psc1/data.json\").read()\n","intents = json.loads(data_file)"],"metadata":{"id":"7GzaEPlv8tcj","executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":14,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4GD6V8gk60_f"},"source":["# 2. Data pre-processing"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"IIOrVh7060_g","executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":14,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}}},"outputs":[],"source":["# preprocessing the json data\n","# tokenization\n","#nltk.download('punkt')\n","#nltk.download('wordnet')\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","\n","        #tokenize each word\n","        w = nltk.word_tokenize(pattern)\n","        words.extend(w)\n","        #add documents in the corpus\n","        documents.append((w, intent['tag']))\n","\n","        # add to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])"]},{"cell_type":"markdown","metadata":{"id":"nHHOkhfU60_h"},"source":["### Tokenisasi\n","\n","- Pada proses tokenisasi pada dasarnya adalah pemisahan kalimat, paragraf,\n","atau seluruh dokumen teks menjadi unit yang lebih kecil, proses itu yang disebut token\n","\n","- Pada proses ini juga akan save documen tersebut menjadi file label.pkl dan texts.pkl (proses labeling)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"7Ympt7GM60_i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":13,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"32083a5d-574d-4f88-d6c5-d026dbd9aa71"},"outputs":[{"output_type":"stream","name":"stdout","text":["33 documents\n","7 classes ['default', 'ertanyaanrekomendasikegiatanhujan', 'pertanyaanrekomendasikegiatanberawan', 'pertanyaanrekomendasikegiatancerah', 'pertanyaanrekomendasikegiatansunrise', 'sapaan', 'terimaKasih']\n","50 unique lemmatized words [',', 'ada', 'apa', 'berawan', 'bisa', 'boleh', 'cerah', 'cocok', 'cuaca', 'di', 'didalam', 'dijelaskan', 'diluar', 'hai', 'hallo', 'halo', 'hari', 'hello', 'helo', 'hujan', 'ini', 'itu', 'kasih', 'kegiatan', 'lagi', 'lakukan', 'luar', 'makasih', 'malam', 'mengerti', 'outdoor', 'pagi', 'rekomendasi', 'ruangan', 'saat', 'saran', 'saya', 'selamat', 'siang', 'sore', 'sunrise', 'tahu', 'terima', 'thank', 'thanks', 'tidak', 'trim', 'untuk', 'yang', 'you']\n"]}],"source":["words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","\n","# sort classes\n","classes = sorted(list(set(classes)))\n","\n","# documents = combination between patterns and intents\n","print (len(documents), \"documents\")\n","\n","# classes = intents\n","print (len(classes), \"classes\", classes)\n","\n","# words = all words, vocabulary\n","print (len(words), \"unique lemmatized words\", words)\n","\n","# creating a pickle file to store the Python objects which we will use while predicting\n","pickle.dump(words,open('texts.pkl','wb'))\n","pickle.dump(classes,open('labels.pkl','wb'))"]},{"cell_type":"markdown","metadata":{"id":"M17p-EqZ60_l"},"source":["# 3. Creating Training Data\n","\n","- Pada dasarnya, bag of words adalah representasi sederhana dari setiap teks dalam sebuah kalimat sebagai bag of words-nya."]},{"cell_type":"code","execution_count":57,"metadata":{"id":"t-JzwVV560_m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701760136816,"user_tz":-420,"elapsed":9,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"2c65e436-1984-417c-da17-a1130a185d22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data created\n"]}],"source":["# create our training data\n","training = []\n","\n","# create an empty array for our output\n","output_empty = [0] * len(classes)\n","\n","# training set, bag of words for each sentence\n","for doc in documents:\n","    # initialize our bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","\n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","\n","    # create our bag of words array with 1, if word match found in current pattern\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","    training.append([bag, output_row])\n","\n","# shuffle features and converting it into numpy arrays\n","random.shuffle(training)\n","training = np.array(training)\n","\n","# create train and test lists\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","\n","print(\"Training data created\")"]},{"cell_type":"markdown","metadata":{"id":"Dbss8sVZ60_n"},"source":["# 5. Creating Modeling\n","\n","- Pada proses ini kami akan membuat model jaringan saraf dan menyimpan model tersebut"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"xY7M8Lbf60_o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701760144432,"user_tz":-420,"elapsed":7623,"user":{"displayName":"Yulia Trisnawati","userId":"14032721064491822168"}},"outputId":"3719196e-cae7-4933-be8a-2931a2daa822"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","7/7 [==============================] - 1s 4ms/step - loss: 1.9766 - accuracy: 0.1515\n","Epoch 2/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.9609 - accuracy: 0.1818\n","Epoch 3/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.8709 - accuracy: 0.2727\n","Epoch 4/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.7317 - accuracy: 0.4242\n","Epoch 5/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.7051 - accuracy: 0.3333\n","Epoch 6/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.6638 - accuracy: 0.3636\n","Epoch 7/200\n","7/7 [==============================] - 0s 5ms/step - loss: 1.5732 - accuracy: 0.3939\n","Epoch 8/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.5406 - accuracy: 0.3939\n","Epoch 9/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.3819 - accuracy: 0.4545\n","Epoch 10/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.5216 - accuracy: 0.3636\n","Epoch 11/200\n","7/7 [==============================] - 0s 5ms/step - loss: 1.3808 - accuracy: 0.4848\n","Epoch 12/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.3325 - accuracy: 0.4848\n","Epoch 13/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.2316 - accuracy: 0.4545\n","Epoch 14/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.0883 - accuracy: 0.7273\n","Epoch 15/200\n","7/7 [==============================] - 0s 5ms/step - loss: 1.0792 - accuracy: 0.5758\n","Epoch 16/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.1548 - accuracy: 0.5152\n","Epoch 17/200\n","7/7 [==============================] - 0s 4ms/step - loss: 1.0826 - accuracy: 0.4848\n","Epoch 18/200\n","7/7 [==============================] - 0s 3ms/step - loss: 1.2179 - accuracy: 0.4848\n","Epoch 19/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7321 - accuracy: 0.7273\n","Epoch 20/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7912 - accuracy: 0.7273\n","Epoch 21/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.7576\n","Epoch 22/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7273\n","Epoch 23/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.8376 - accuracy: 0.6667\n","Epoch 24/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.7273\n","Epoch 25/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.7273\n","Epoch 26/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7186 - accuracy: 0.7273\n","Epoch 27/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.8006 - accuracy: 0.7576\n","Epoch 28/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7178 - accuracy: 0.7273\n","Epoch 29/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8485\n","Epoch 30/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7879\n","Epoch 31/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7576\n","Epoch 32/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7576\n","Epoch 33/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.6956 - accuracy: 0.7273\n","Epoch 34/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.6970\n","Epoch 35/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.9091\n","Epoch 36/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7879\n","Epoch 37/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.8485\n","Epoch 38/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8788\n","Epoch 39/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.8485\n","Epoch 40/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8182\n","Epoch 41/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7879\n","Epoch 42/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8485\n","Epoch 43/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8788\n","Epoch 44/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8485\n","Epoch 45/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.9091\n","Epoch 46/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8788\n","Epoch 47/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8788\n","Epoch 48/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8485\n","Epoch 49/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8485\n","Epoch 50/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7879\n","Epoch 51/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8182\n","Epoch 52/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8788\n","Epoch 53/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8485\n","Epoch 54/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8788\n","Epoch 55/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8788\n","Epoch 56/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8788\n","Epoch 57/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8788\n","Epoch 58/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7879\n","Epoch 59/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2843 - accuracy: 0.8788\n","Epoch 60/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.9091\n","Epoch 61/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8485\n","Epoch 62/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8788\n","Epoch 63/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8485\n","Epoch 64/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8788\n","Epoch 65/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9091\n","Epoch 66/200\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3171 - accuracy: 0.8788\n","Epoch 67/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.9091\n","Epoch 68/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.7879\n","Epoch 69/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9394\n","Epoch 70/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8485\n","Epoch 71/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8485\n","Epoch 72/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.9394\n","Epoch 73/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2201 - accuracy: 0.9091\n","Epoch 74/200\n","7/7 [==============================] - 0s 6ms/step - loss: 0.2538 - accuracy: 0.8788\n","Epoch 75/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.7879\n","Epoch 76/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9394\n","Epoch 77/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9394\n","Epoch 78/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8485\n","Epoch 79/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9394\n","Epoch 80/200\n","7/7 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8485\n","Epoch 81/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8788\n","Epoch 82/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.9091\n","Epoch 83/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8788\n","Epoch 84/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.9091\n","Epoch 85/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.8788\n","Epoch 86/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.8788\n","Epoch 87/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.8485\n","Epoch 88/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.9091\n","Epoch 89/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.8788\n","Epoch 90/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9091\n","Epoch 91/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9394\n","Epoch 92/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9091\n","Epoch 93/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.9091\n","Epoch 94/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.8485\n","Epoch 95/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9394\n","Epoch 96/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8788\n","Epoch 97/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8788\n","Epoch 98/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.9091\n","Epoch 99/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2613 - accuracy: 0.8788\n","Epoch 100/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9091\n","Epoch 101/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9697\n","Epoch 102/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9091\n","Epoch 103/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2898 - accuracy: 0.9091\n","Epoch 104/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9091\n","Epoch 105/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9091\n","Epoch 106/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2327 - accuracy: 0.9394\n","Epoch 107/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9091\n","Epoch 108/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9091\n","Epoch 109/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.8788\n","Epoch 110/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.8788\n","Epoch 111/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.9091\n","Epoch 112/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.9091\n","Epoch 113/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.8788\n","Epoch 114/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.8788\n","Epoch 115/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8788\n","Epoch 116/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8788\n","Epoch 117/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.8788\n","Epoch 118/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2269 - accuracy: 0.9091\n","Epoch 119/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9091\n","Epoch 120/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.8788\n","Epoch 121/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9091\n","Epoch 122/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.8485\n","Epoch 123/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.9091\n","Epoch 124/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8788\n","Epoch 125/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9091\n","Epoch 126/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9091\n","Epoch 127/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8788\n","Epoch 128/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8788\n","Epoch 129/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9091\n","Epoch 130/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.8788\n","Epoch 131/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2171 - accuracy: 0.9091\n","Epoch 132/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.8788\n","Epoch 133/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.8788\n","Epoch 134/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9091\n","Epoch 135/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1854 - accuracy: 0.8788\n","Epoch 136/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.7879\n","Epoch 137/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9394\n","Epoch 138/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.8485\n","Epoch 139/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9394\n","Epoch 140/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1832 - accuracy: 0.9394\n","Epoch 141/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9091\n","Epoch 142/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2042 - accuracy: 0.9091\n","Epoch 143/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9697\n","Epoch 144/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.9394\n","Epoch 145/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.8788\n","Epoch 146/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.8788\n","Epoch 147/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9091\n","Epoch 148/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.8788\n","Epoch 149/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9394\n","Epoch 150/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9394\n","Epoch 151/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9091\n","Epoch 152/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9091\n","Epoch 153/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.9697\n","Epoch 154/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2364 - accuracy: 0.8788\n","Epoch 155/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.8788\n","Epoch 156/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9394\n","Epoch 157/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.8485\n","Epoch 158/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2197 - accuracy: 0.8788\n","Epoch 159/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9394\n","Epoch 160/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.9394\n","Epoch 161/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9394\n","Epoch 162/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9091\n","Epoch 163/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.8788\n","Epoch 164/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2241 - accuracy: 0.9394\n","Epoch 165/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.8788\n","Epoch 166/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.8788\n","Epoch 167/200\n","7/7 [==============================] - 0s 6ms/step - loss: 0.1649 - accuracy: 0.9394\n","Epoch 168/200\n","7/7 [==============================] - 0s 6ms/step - loss: 0.2748 - accuracy: 0.8788\n","Epoch 169/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.8788\n","Epoch 170/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9091\n","Epoch 171/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.8485\n","Epoch 172/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.8788\n","Epoch 173/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9091\n","Epoch 174/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.8788\n","Epoch 175/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.8788\n","Epoch 176/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8485\n","Epoch 177/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.8788\n","Epoch 178/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.9394\n","Epoch 179/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1833 - accuracy: 0.9394\n","Epoch 180/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2177 - accuracy: 0.8788\n","Epoch 181/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.8485\n","Epoch 182/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9091\n","Epoch 183/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.9394\n","Epoch 184/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.9091\n","Epoch 185/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.8788\n","Epoch 186/200\n","7/7 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8788\n","Epoch 187/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9091\n","Epoch 188/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9091\n","Epoch 189/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2083 - accuracy: 0.9394\n","Epoch 190/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.8788\n","Epoch 191/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.8788\n","Epoch 192/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9091\n","Epoch 193/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.9394\n","Epoch 194/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9091\n","Epoch 195/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.2244 - accuracy: 0.8788\n","Epoch 196/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9394\n","Epoch 197/200\n","7/7 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9394\n","Epoch 198/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9091\n","Epoch 199/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.1955 - accuracy: 0.8788\n","Epoch 200/200\n","7/7 [==============================] - 0s 5ms/step - loss: 0.2142 - accuracy: 0.8788\n","\n","\n","**************************************************\n","\n","Model Created Successfully!\n"]}],"source":["# Create NN model to predict the responses\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))\n","\n","# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n","sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","\n","#fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('models.h5', hist) # we will pickle this model to use in the future\n","print(\"\\n\")\n","print(\"*\"*50)\n","print(\"\\nModel Created Successfully!\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('prakerja')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1e0f4fe6ccee135700700c04fb47eca4b2c8b959d86ecafd53b43ebd6f201da1"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}